{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be523e3-cd14-4a55-ad5b-dabd413eef7e",
   "metadata": {},
   "source": [
    "### Importing libraries\n",
    "Necessary python libraries to be used in this project: Pytorch, OpenCV, Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e318c74-acd5-4b9e-b5cd-8c4cd1414aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing PyTorch and torchvision for deep learning\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim  \n",
    "import torchvision  \n",
    "import torchvision.transforms as transforms  \n",
    "\n",
    "# Importing PIL for image handling\n",
    "from PIL import Image\n",
    "\n",
    "# Importing OpenCV for image processing\n",
    "import cv2\n",
    "\n",
    "# Importing Numpy for numerical operations\n",
    "import numpy as np  \n",
    "\n",
    "# Importing OS and glob for file handling\n",
    "import os  \n",
    "import glob  \n",
    "import shutil \n",
    "\n",
    "# Importing dataset utilities from torchvision\n",
    "from torchvision import datasets, models  \n",
    "from torch.utils.data import DataLoader, random_split  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ba3436-27fa-47b8-98b9-8b99e3d7fa65",
   "metadata": {},
   "source": [
    "### Severity classification\n",
    "Classifying images in \"Powdery Mildew\" into two levels namely; \"Mild\" and \"Severe\", based on leaf infection percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf1075b-0016-4537-a54f-5587edd27e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Severity thresholds for classification based on infection percentage\n",
    "SEVERITY_THRESHOLDS = {\n",
    "    \"Mild\": (0, 50), # Infection percentage between 0% and 50% is classified as Mild\n",
    "    \"Severe\": (50, 100) # Infection percentage between 50% and 100% is classified as Severe\n",
    "}\n",
    "\n",
    "def calculate_infection_percentage(image_path):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of infected pixels in an image.\n",
    "    \n",
    "    The function converts the image to HSV and applies a color threshold to \n",
    "    detect white fungal regions.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "    \n",
    "    Returns:\n",
    "        float: Percentage of infected pixels.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path) # Read an image\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) # Convert to HSV \n",
    "\n",
    "    # Defining the HSV range for detecting infected regions\n",
    "    lower_white = np.array([0, 0, 160], dtype=np.uint8)\n",
    "    upper_white = np.array([255, 40, 255], dtype=np.uint8)\n",
    "\n",
    "    # Binary mask where white regions are detected\n",
    "    mask = cv2.inRange(hsv, lower_white, upper_white)\n",
    "\n",
    "    # Calculating total and infected pixels\n",
    "    total_pixels = mask.size\n",
    "    infected_pixels = np.count_nonzero(mask)\n",
    "\n",
    "    # Computing infection percentage\n",
    "    return (infected_pixels / total_pixels) * 100\n",
    "\n",
    "def classify_severity(image_path):\n",
    "    \"\"\"\n",
    "    Classifies the severity of Powdery Mildew infection based on infection percentage.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        str or None: Returns \"Mild\" or \"Severe\" based on thresholds, or None if undefined.\n",
    "    \"\"\"\n",
    "    percentage = calculate_infection_percentage(image_path)\n",
    "    \n",
    "    # Determining severity category based on infection percentage\n",
    "    for severity, (lower, upper) in SEVERITY_THRESHOLDS.items():\n",
    "        if lower <= percentage < upper:\n",
    "            return severity\n",
    "    return None\n",
    "\n",
    "# Input and output directories\n",
    "input_directory = r\"D:\\Computer Science Y4\\CS Y4S2\\Project II\\Deep-Learning-for-Powdery-Mildew-Disease-Detection-in-mango-leaves\\MangoLeaf Dataset\\Powdery Mildew\"\n",
    "output_directory = r\"D:\\Computer Science Y4\\CS Y4S2\\Project II\\Deep-Learning-for-Powdery-Mildew-Disease-Detection-in-mango-leaves\\MangoLeaf Dataset\\Severity_Dataset\"\n",
    "\n",
    "# Subdirectories for each severity category\n",
    "for severity in SEVERITY_THRESHOLDS.keys():\n",
    "    os.makedirs(os.path.join(output_directory, severity), exist_ok=True)\n",
    "\n",
    "# Looping through images in the input directory and classifying them\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        img_path = os.path.join(input_directory, filename)\n",
    "        severity = classify_severity(img_path)\n",
    "        if severity:\n",
    "            # Moving each image to the corresponding severity folder\n",
    "            shutil.copy(img_path, os.path.join(output_directory, severity, filename))\n",
    "\n",
    "print(\"Severity classification complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ac3e54-5bf7-4f09-9e17-0eab852baebc",
   "metadata": {},
   "source": [
    "### Augmentation\n",
    "Oversampling images in under-represented classes using data augmentation, to ensures that each class in the dataset has 5000 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76d3371b-7668-4995-8641-6f31562125e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset balancing complete! All classes now have 5000 images.\n"
     ]
    }
   ],
   "source": [
    "# Defining dataset directory and target class sizes(5000 images)\n",
    "dataset_dir = r\"D:\\Computer Science Y4\\CS Y4S2\\Project II\\Deep-Learning-for-Powdery-Mildew-Disease-Detection-in-mango-leaves\\MangoLeaf Dataset\"\n",
    "classes = [\"Healthy\", \"Mild\", \"Severe\"]\n",
    "target_size = 5000  \n",
    "\n",
    "# Augmentation transformations\n",
    "augment = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), shear=0.2),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.7, contrast=0.2),\n",
    "    transforms.RandomHorizontalFlip()\n",
    "])\n",
    "\n",
    "# Data augmentation for undersampled classes\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    images = glob.glob(os.path.join(class_dir, \"*.jpg\"))\n",
    "    current_size = len(images)\n",
    "\n",
    "    # Augment images to the target sizes\n",
    "    if current_size < target_size:\n",
    "        extra_needed = target_size - current_size\n",
    "\n",
    "        for i in range(extra_needed):\n",
    "            img_path = images[i % current_size] \n",
    "            image = Image.open(img_path)\n",
    "            \n",
    "            augmented_image = augment(image)\n",
    "            new_img_name = os.path.join(class_dir, f\"aug_{i+1}.jpg\")\n",
    "            augmented_image.save(new_img_name)\n",
    "\n",
    "        print(f\"Oversampled {class_name} to 5000 images.\")\n",
    "\n",
    "print(\"Dataset balancing complete! All classes now have 5000 images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2032741e-c3a8-41cb-adaf-7d4bb17e29ad",
   "metadata": {},
   "source": [
    "### Dataset Splitting\n",
    "Splitting Dataset into Training(70%), Validation(20%) and Testing(10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "643ff9e5-143e-409f-a581-9c86197902f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete! \n",
      "Train: 10500 \n",
      "Validation: 3000 \n",
      "Test: 1500\n"
     ]
    }
   ],
   "source": [
    "# Dataset directory and batch size\n",
    "dataset_dir = r'D:\\Computer Science Y4\\CS Y4S2\\Project II\\Deep-Learning-for-Powdery-Mildew-Disease-Detection-in-mango-leaves\\MangoLeaf Dataset'\n",
    "batch_size = 32\n",
    "num_classes = 3 # Number of classification categories\n",
    "\n",
    "# Transformations: resize, convert to tensor, and normalize\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Loading dataset and applying transformations\n",
    "dataset = datasets.ImageFolder(root=dataset_dir, transform=data_transforms)\n",
    "\n",
    "# Splitting dataset into training (70%), validation (20%), and testing (10%)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# Dataset splitting\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Data loaders for batching and shuffling\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Dataset split complete! \\nTrain: {train_size} \\nValidation: {val_size} \\nTest: {test_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b4469a-f90b-4cb1-babb-0ecda4e54dcc",
   "metadata": {},
   "source": [
    "### Loading Pretrained ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6434514-f181-4510-a10b-7ca26e10a223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18 model is ready for transfer learning!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Loading pre-trained ResNet18 model with default weights\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Freezing all layers to retain pre-trained features\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  \n",
    "\n",
    "# Modifying the fully connected layer to match the number of classes\n",
    "num_features = model.fc.in_features # Get the number of input features in the FC layer\n",
    "num_classes = 3  # Number of output classes\n",
    "model.fc = nn.Linear(num_features, num_classes) # Replace FC layer with a new one\n",
    "\n",
    "# Move model to the specified device\n",
    "model = model.to(device)\n",
    "print(\"ResNet18 model is ready for transfer learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121eed39-1f51-423d-b9c4-329f92bbc1f2",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd9a8a6b-f02f-48de-9817-a96c19eee6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Train -> Loss: 0.7315, Accuracy: 0.7370\n",
      "  Val   -> Loss: 0.5255, Accuracy: 0.8460, Precision: 0.8449, Recall: 0.8470, F1-score: 0.8441\n",
      "Epoch 2:\n",
      "  Train -> Loss: 0.4601, Accuracy: 0.8657\n",
      "  Val   -> Loss: 0.3906, Accuracy: 0.8793, Precision: 0.8794, Recall: 0.8793, F1-score: 0.8792\n",
      "Epoch 3:\n",
      "  Train -> Loss: 0.3709, Accuracy: 0.8858\n",
      "  Val   -> Loss: 0.3292, Accuracy: 0.9000, Precision: 0.9000, Recall: 0.9001, F1-score: 0.9000\n",
      "Epoch 4:\n",
      "  Train -> Loss: 0.3307, Accuracy: 0.8956\n",
      "  Val   -> Loss: 0.2923, Accuracy: 0.9043, Precision: 0.9044, Recall: 0.9047, F1-score: 0.9044\n",
      "Epoch 5:\n",
      "  Train -> Loss: 0.2990, Accuracy: 0.9002\n",
      "  Val   -> Loss: 0.2814, Accuracy: 0.9003, Precision: 0.9038, Recall: 0.9014, F1-score: 0.9001\n",
      "Epoch 6:\n",
      "  Train -> Loss: 0.2789, Accuracy: 0.9044\n",
      "  Val   -> Loss: 0.2530, Accuracy: 0.9157, Precision: 0.9157, Recall: 0.9158, F1-score: 0.9157\n",
      "Epoch 7:\n",
      "  Train -> Loss: 0.2646, Accuracy: 0.9064\n",
      "  Val   -> Loss: 0.2448, Accuracy: 0.9150, Precision: 0.9154, Recall: 0.9154, F1-score: 0.9151\n",
      "Epoch 8:\n",
      "  Train -> Loss: 0.2555, Accuracy: 0.9085\n",
      "  Val   -> Loss: 0.2357, Accuracy: 0.9177, Precision: 0.9174, Recall: 0.9179, F1-score: 0.9176\n",
      "Epoch 9:\n",
      "  Train -> Loss: 0.2462, Accuracy: 0.9109\n",
      "  Val   -> Loss: 0.2269, Accuracy: 0.9210, Precision: 0.9211, Recall: 0.9211, F1-score: 0.9211\n",
      "Epoch 10:\n",
      "  Train -> Loss: 0.2383, Accuracy: 0.9130\n",
      "  Val   -> Loss: 0.2265, Accuracy: 0.9173, Precision: 0.9186, Recall: 0.9179, F1-score: 0.9175\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 10 # Number of training epochs\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # Training phase\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct_train += (preds == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    train_loss = total_train_loss / len(train_loader) # Computing average training loss\n",
    "    train_acc = correct_train / total_train # Computing training accuracy\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    tp = torch.zeros(3, device=device)\n",
    "    fp = torch.zeros(3, device=device)\n",
    "    fn = torch.zeros(3, device=device)\n",
    "\n",
    "    # Validation phase\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct_val += (preds == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "            # Compute TP, FP, FN for each class\n",
    "            for i in range(3):  \n",
    "                tp[i] += ((preds == i) & (labels == i)).sum()\n",
    "                fp[i] += ((preds == i) & (labels != i)).sum()\n",
    "                fn[i] += ((preds != i) & (labels == i)).sum()\n",
    "\n",
    "    val_loss = total_val_loss / len(val_loader) # Computeing average validation loss\n",
    "    val_acc = correct_val / total_val # Computing validation accuracy\n",
    "\n",
    "    # Computing Precision, Recall, and F1-score for each class\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "    # Computing average metrics across all classes\n",
    "    val_precision = precision.mean().item()\n",
    "    val_recall = recall.mean().item()\n",
    "    val_f1 = f1_score.mean().item()\n",
    "\n",
    "    # Printing training and validation metrics\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    print(f\"  Train -> Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"  Val   -> Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1-score: {val_f1:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaa47d9-3459-4930-8f3b-9053f3340688",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f524324f-27f8-4780-806b-6923c2e1fca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.22663296917651563, Test Accuracy: 91.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss, correct, total = 0, 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "# Computing test accuracy\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Loss: {test_loss/len(test_loader)}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae8e3c54-53b4-4580-b139-4a3098207354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Saving the trained model's state dictionary\n",
    "torch.save(model.state_dict(), \"resnet18_model.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056a6d1-70df-43fb-8a49-4b62abcbfa52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
